{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3303dfd",
   "metadata": {},
   "source": [
    "## 정규표현식(regular expression, Regexp)\n",
    "\n",
    "- 특정 문자들을 지정, 추가, 삭제 가능\n",
    "- 데이터 전처리에서 정규표현식을 많이 사용\n",
    "- re: 파이썬에서 정규표현식을 지원하는 패키지 \n",
    "\n",
    "### 정규표현식 문법\n",
    "특수 문자 | 설명 \n",
    "------|--------\n",
    ". | 앞의 문자 1개 표현\n",
    "? | 문자 한개를 표현하나 존재할 수도, 존재하지 않을 수도 있음(0개 1개)\n",
    "$*$ | 앞의 문자가 0개 이상\n",
    "$+$ | 앞의 문자가 최소 1개 이상\n",
    "^ | 뒤의 문자로 문자열이 시작\n",
    "\\$ | 앞의 문자로 문자열이 끝남\n",
    "\\{n\\} | n번만큼 반복\n",
    "\\{n1, n2\\} | n1이상, n2이하만큼 반복, n2를 지정하지 않으면 n1 이상만 반복\n",
    "\\[ abc \\] | 안에 문자들 중 한 개의 문자와 매치, a-z처럼 범위도 지정 가능\n",
    "\\[ ^a \\] | 해당 문자를 제외하고 매치\n",
    "a:b | a 또는 b를 나타냄\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c536e24",
   "metadata": {},
   "source": [
    "### 정규 표현식에 자주 사용하는 역슬래시를 이용한 문자 규칙\n",
    "\n",
    "문자 | 설명\n",
    "------|--------\n",
    "\\\\\\ | 역슬래시 자체를 의미\n",
    "\\d | 모든 숫자를 의미, [0-9]와 동일\n",
    "\\D | 숫자를 제외한 모든 문자를 의미, [^0-9]와 동일\n",
    "\\s | 공백을 의미, [\\t\\n\\r\\f\\v]와 동일\n",
    "\\S | 공벡을 제외한 모든 문자를 의미, [^\\t\\n\\r\\f\\v]와 동일\n",
    "\\w | 문자와 숫자를 의미, [a-ZA-Z0-9]와 동일\n",
    "\\W | 문자와 숫자를 제외한 다른 문자를 의미, [a-ZA-Z0-9]와 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f581b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # 정규 표현식 패키지 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "951b978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "빅통분 = \"\"\"이 강의에서는 Windows 10, 11 하에서 Apache에서 제공하는 다양한 빅데이터처리 툴(Hadoop, Spark, Kafka 등)을 \n",
    "설치하고 환경 설정하는 작업을 직접 수행하기 때문에 컴퓨터에 대한 사전 지식이 없는 경우 수강하기 어려움. \n",
    "빅데이터의 특징인 3V와 같이 이 교과에서는 상당한 양과 다양한 내용을 빠르게 강의하기 때문에\n",
    "강의를 수강하는데 필요한 통계 지식(회귀분석, 다변량분석 등)을 사전에 알고 있어야 함. \n",
    "일부 R이나 scala도 사용하는 경우도 있으나 기본 프로그램 언어는 python이며 python에 대해 기본적인 내용은 알고 있어야 함.\n",
    "모든 프로젝트는 개인별로 평가를 받으며 별도의 팀프로젝트 없음.\n",
    "모든 프로그램은 직접 코딩해야 함(소스 코드는 워터마크가 숨겨진 이미지 형태로 제공).\n",
    "\"\"\"\n",
    "\n",
    "예제문장 =  ['This is the first document.', 'This document is the second document.', \n",
    "         'And this is the third one.', 'Is this the first document?']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72618239",
   "metadata": {},
   "source": [
    "### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a67e3cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이',\n",
       " '강의에서는',\n",
       " 'Windows',\n",
       " '10,',\n",
       " '11',\n",
       " '하에서',\n",
       " 'Apache에서',\n",
       " '제공하는',\n",
       " '다양한',\n",
       " '빅데이터처리',\n",
       " '툴(Hadoop,',\n",
       " 'Spark,',\n",
       " 'Kafka',\n",
       " '등)을',\n",
       " '설치하고',\n",
       " '환경',\n",
       " '설정하는',\n",
       " '작업을',\n",
       " '직접',\n",
       " '수행하기',\n",
       " '때문에',\n",
       " '컴퓨터에',\n",
       " '대한',\n",
       " '사전',\n",
       " '지식이',\n",
       " '없는',\n",
       " '경우',\n",
       " '수강하기',\n",
       " '어려움.',\n",
       " '빅데이터의',\n",
       " '특징인',\n",
       " '3V와',\n",
       " '같이',\n",
       " '이',\n",
       " '교과에서는',\n",
       " '상당한',\n",
       " '양과',\n",
       " '다양한',\n",
       " '내용을',\n",
       " '빠르게',\n",
       " '강의하기',\n",
       " '때문에',\n",
       " '강의를',\n",
       " '수강하는데',\n",
       " '필요한',\n",
       " '통계',\n",
       " '지식(회귀분석,',\n",
       " '다변량분석',\n",
       " '등)을',\n",
       " '사전에',\n",
       " '알고',\n",
       " '있어야',\n",
       " '함.',\n",
       " '일부',\n",
       " 'R이나',\n",
       " 'scala도',\n",
       " '사용하는',\n",
       " '경우도',\n",
       " '있으나',\n",
       " '기본',\n",
       " '프로그램',\n",
       " '언어는',\n",
       " 'python이며',\n",
       " 'python에',\n",
       " '대해',\n",
       " '기본적인',\n",
       " '내용은',\n",
       " '알고',\n",
       " '있어야',\n",
       " '함.',\n",
       " '모든',\n",
       " '프로젝트는',\n",
       " '개인별로',\n",
       " '평가를',\n",
       " '받으며',\n",
       " '별도의',\n",
       " '팀프로젝트',\n",
       " '없음.',\n",
       " '모든',\n",
       " '프로그램은',\n",
       " '직접',\n",
       " '코딩해야',\n",
       " '함(소스',\n",
       " '코드는',\n",
       " '워터마크가',\n",
       " '숨겨진',\n",
       " '이미지',\n",
       " '형태로',\n",
       " '제공).']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "빅통분.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e742021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이',\n",
       " '강의에서는',\n",
       " 'Windows',\n",
       " '10,',\n",
       " '11',\n",
       " '하에서',\n",
       " 'Apache에서',\n",
       " '제공하는',\n",
       " '다양한',\n",
       " '빅데이터처리',\n",
       " '툴(Hadoop,',\n",
       " 'Spark,',\n",
       " 'Kafka',\n",
       " '등)을',\n",
       " '\\n설치하고',\n",
       " '환경',\n",
       " '설정하는',\n",
       " '작업을',\n",
       " '직접',\n",
       " '수행하기',\n",
       " '때문에',\n",
       " '컴퓨터에',\n",
       " '대한',\n",
       " '사전',\n",
       " '지식이',\n",
       " '없는',\n",
       " '경우',\n",
       " '수강하기',\n",
       " '어려움.',\n",
       " '\\n빅데이터의',\n",
       " '특징인',\n",
       " '3V와',\n",
       " '같이',\n",
       " '이',\n",
       " '교과에서는',\n",
       " '상당한',\n",
       " '양과',\n",
       " '다양한',\n",
       " '내용을',\n",
       " '빠르게',\n",
       " '강의하기',\n",
       " '때문에\\n강의를',\n",
       " '수강하는데',\n",
       " '필요한',\n",
       " '통계',\n",
       " '지식(회귀분석,',\n",
       " '다변량분석',\n",
       " '등)을',\n",
       " '사전에',\n",
       " '알고',\n",
       " '있어야',\n",
       " '함.',\n",
       " '\\n일부',\n",
       " 'R이나',\n",
       " 'scala도',\n",
       " '사용하는',\n",
       " '경우도',\n",
       " '있으나',\n",
       " '기본',\n",
       " '프로그램',\n",
       " '언어는',\n",
       " 'python이며',\n",
       " 'python에',\n",
       " '대해',\n",
       " '기본적인',\n",
       " '내용은',\n",
       " '알고',\n",
       " '있어야',\n",
       " '함.\\n모든',\n",
       " '프로젝트는',\n",
       " '개인별로',\n",
       " '평가를',\n",
       " '받으며',\n",
       " '별도의',\n",
       " '팀프로젝트',\n",
       " '없음.\\n모든',\n",
       " '프로그램은',\n",
       " '직접',\n",
       " '코딩해야',\n",
       " '함(소스',\n",
       " '코드는',\n",
       " '워터마크가',\n",
       " '숨겨진',\n",
       " '이미지',\n",
       " '형태로',\n",
       " '제공).\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#re 방법을 통해서 \"스페이스\" 기준으로 텍스트를 분리 => '\\n'을 포함해서 단어를 분리\n",
    "r = re.compile(\" \")\n",
    "r.split(빅통분)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4179087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이 강의에서는 Windows ',\n",
       " '',\n",
       " ', ',\n",
       " '',\n",
       " ' 하에서 Apache에서 제공하는 다양한 빅데이터처리 툴(Hadoop, Spark, Kafka 등)을 \\n설치하고 환경 설정하는 작업을 직접 수행하기 때문에 컴퓨터에 대한 사전 지식이 없는 경우 수강하기 어려움. \\n빅데이터의 특징인 ',\n",
       " 'V와 같이 이 교과에서는 상당한 양과 다양한 내용을 빠르게 강의하기 때문에\\n강의를 수강하는데 필요한 통계 지식(회귀분석, 다변량분석 등)을 사전에 알고 있어야 함. \\n일부 R이나 scala도 사용하는 경우도 있으나 기본 프로그램 언어는 python이며 python에 대해 기본적인 내용은 알고 있어야 함.\\n모든 프로젝트는 개인별로 평가를 받으며 별도의 팀프로젝트 없음.\\n모든 프로그램은 직접 코딩해야 함(소스 코드는 워터마크가 숨겨진 이미지 형태로 제공).\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#re 패키지를 사용하여 \"숫자\" 기준으로 텍스트 분리 -> 숫자가 없는 데이터들로 구성 \n",
    "r = re.compile(\"[0-9]\")\n",
    "r.split(빅통분)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0452a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공백 (\\t \\n \\r \\f \\v)을 기준으로 데이터 분리\n",
    "r = re.compile(\"\\s\")\n",
    "r.split(빅통분)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c41c7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m r \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m예제문장\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "#re 패키지는 리스트에서는 적용이 되지 않고, 하나로 이어진 문자열에 대해서만 실행됨\n",
    "r = re.compile(\" \")\n",
    "r.split(예제문장) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75de427e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first document.\n",
      "This document is the second document.\n",
      "And this is the third one.\n",
      "Is this the first document?\n"
     ]
    }
   ],
   "source": [
    "#리스트의 각 문장들을 join 함수를 통해 \"\\n\"을 붙여 결합 -> 하나의 데이터로 생성\n",
    "결합문장 = \"\\n\".join(예제문장)\n",
    "print(결합문장)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0e4acf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'first',\n",
       " 'document.',\n",
       " 'This',\n",
       " 'document',\n",
       " 'is',\n",
       " 'the',\n",
       " 'second',\n",
       " 'document.',\n",
       " 'And',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'third',\n",
       " 'one.',\n",
       " 'Is',\n",
       " 'this',\n",
       " 'the',\n",
       " 'first',\n",
       " 'document?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = re.compile(\"\\s\") #스페이스 기준으로 데이터 분리\n",
    "r.split(결합문장)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17eb3e0",
   "metadata": {},
   "source": [
    "### 단어 토큰화\n",
    "\n",
    "- split\n",
    "- nltk 패키지의 tokenized 모듈 내 word_tokenize() 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ec121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59517f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\SM-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰화 작업을 위해 'punkt' 파일이 필요(\"한번만 실행\")\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60dc0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize #토큰화 하기 위해 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4da2e4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'first',\n",
       " 'document',\n",
       " '.',\n",
       " 'This',\n",
       " 'document',\n",
       " 'is',\n",
       " 'the',\n",
       " 'second',\n",
       " 'document',\n",
       " '.',\n",
       " 'And',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'third',\n",
       " 'one',\n",
       " '.',\n",
       " 'Is',\n",
       " 'this',\n",
       " 'the',\n",
       " 'first',\n",
       " 'document',\n",
       " '?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "토큰 = word_tokenize(결합문장) # 결합문장에서 \"단어\" 단위로 토큰화 -> 토큰 생성\n",
    "토큰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a51c7db",
   "metadata": {},
   "source": [
    "### 문장 토큰화\n",
    "\n",
    "- re.compile(\"\\s\")\n",
    "- nltk 패키지의 tokenized 모듈 내 sent_tokenize() 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30c6fafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the first document.',\n",
       " 'This document is the second document.',\n",
       " 'And this is the third one.',\n",
       " 'Is this the first document?']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "토큰 = sent_tokenize(결합문장) # \"문장\" 자체를 하나씩 가져오도록 토큰화 \n",
    "토큰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f1af3e",
   "metadata": {},
   "source": [
    "### 정규표현식을 이용한 토큰화\n",
    "\n",
    "- re.compile\n",
    "- nltk 패키지의 tokenized 모듈 내 RegexpTokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28826642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python\\'s favorite food is perl. \"Python is very easy.\" he says.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰화할 때 \"불용어\"(특수기호)까지 삭제하고 싶은 경우 해당 패키지 사용\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "예시 = \"Python's favorite food is perl. \\\"Python is very easy.\\\" he says.\"\n",
    "예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f863b530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 's',\n",
       " 'favorite',\n",
       " 'food',\n",
       " 'is',\n",
       " 'perl',\n",
       " 'Python',\n",
       " 'is',\n",
       " 'very',\n",
       " 'easy',\n",
       " 'he',\n",
       " 'says']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "토큰화 = RegexpTokenizer(\"[\\w]+\") # 문자와 숫자를 제외한 나머지는 다 제거\n",
    "토큰 = 토큰화.tokenize(예시)\n",
    "토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86f25b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이',\n",
       " '강의에서는',\n",
       " 'Windows',\n",
       " '10',\n",
       " '11',\n",
       " '하에서',\n",
       " 'Apache에서',\n",
       " '제공하는',\n",
       " '다양한',\n",
       " '빅데이터처리',\n",
       " '툴',\n",
       " 'Hadoop',\n",
       " 'Spark',\n",
       " 'Kafka',\n",
       " '등',\n",
       " '을',\n",
       " '설치하고',\n",
       " '환경',\n",
       " '설정하는',\n",
       " '작업을',\n",
       " '직접',\n",
       " '수행하기',\n",
       " '때문에',\n",
       " '컴퓨터에',\n",
       " '대한',\n",
       " '사전',\n",
       " '지식이',\n",
       " '없는',\n",
       " '경우',\n",
       " '수강하기']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 특수문자 포함 -> # 문자와 숫자를 제외한 나머지는 다 제거\n",
    "토큰화 = RegexpTokenizer(\"[\\w]+\")\n",
    "토큰 = 토큰화.tokenize(빅통분) # 토큰화해주는 함수에 적용\n",
    "토큰[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5875a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Windows',\n",
       " 'Apache',\n",
       " 'Hadoop',\n",
       " 'Spark',\n",
       " 'Kafka',\n",
       " 'V',\n",
       " 'R',\n",
       " 'scala',\n",
       " 'python',\n",
       " 'python']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "토큰화 = RegexpTokenizer(\"[a-zA-Z]+\") # 첫글자부터 마지막 글자까지 전체 한글만 뽑아냄 (영어, 숫자 다 제거) \n",
    "#ㅋㅋㅋ 을 출력하려면 [ㄱ -ㅎ ] 를 작성 # \"[a-zA-Z]\"  , \"[가-힣]+\"\n",
    "토큰 = 토큰화.tokenize(빅통분)\n",
    "토큰[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "857837f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Python's\",\n",
       " 'favorite',\n",
       " 'food',\n",
       " 'is',\n",
       " 'perl.',\n",
       " '\"Python',\n",
       " 'is',\n",
       " 'very',\n",
       " 'easy.\"',\n",
       " 'he',\n",
       " 'says.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 특수문자 포함 - RegexpTokenizer() 을 사용하면 원하는 옵션으로 데이터를 split할 수 있음 \n",
    "토큰화 = RegexpTokenizer(\"[\\s]+\",gaps=True)\n",
    "토큰 = 토큰화.tokenize(예시)\n",
    "토큰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dc8658",
   "metadata": {},
   "source": [
    "#### 기타 Tokenizer\n",
    "- WhiteSpaceTokenizer : 공백 기준으로 토큰화\n",
    "- WordPunktTokenizer : Text를 알파벳 문자, 숫자, 알파벡 이외의 문자 리스트로 토큰화\n",
    "- MWETokenizer : 여러 단어를 하나의 개체(Multi-Word Expression)로 토큰화, 예 United States of America\n",
    "-TweetTokenizer : 트위터에서 사용되는 문장을 토큰화 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd6722b",
   "metadata": {},
   "source": [
    "### n-gram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00d634f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x1df9872c040>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ngrams # 데이터를 2개씩 묶어서 표현\n",
    "\n",
    "bigram = ngrams(결합문장.split(),2)\n",
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4c294ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'is'),\n",
       " ('is', 'the'),\n",
       " ('the', 'first'),\n",
       " ('first', 'document.'),\n",
       " ('document.', 'This'),\n",
       " ('This', 'document'),\n",
       " ('document', 'is'),\n",
       " ('is', 'the'),\n",
       " ('the', 'second'),\n",
       " ('second', 'document.'),\n",
       " ('document.', 'And'),\n",
       " ('And', 'this'),\n",
       " ('this', 'is'),\n",
       " ('is', 'the'),\n",
       " ('the', 'third'),\n",
       " ('third', 'one.'),\n",
       " ('one.', 'Is'),\n",
       " ('Is', 'this'),\n",
       " ('this', 'the'),\n",
       " ('the', 'first'),\n",
       " ('first', 'document?')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigram) # 다른 데이터와 합쳤을 때 의미가 생기는 데이터가 있기 때문에 ngrams를 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9730f534",
   "metadata": {},
   "source": [
    "### PoS(Parts of Speech) 태킹: 품사\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d870874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\SM-PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 한번만 실행\n",
    "#nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "474018b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('first', 'JJ'),\n",
       " ('document', 'NN'),\n",
       " ('.', '.'),\n",
       " ('This', 'DT'),\n",
       " ('document', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('second', 'JJ'),\n",
       " ('document', 'NN'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('third', 'JJ'),\n",
       " ('one', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Is', 'VBZ'),\n",
       " ('this', 'DT'),\n",
       " ('the', 'DT'),\n",
       " ('first', 'JJ'),\n",
       " ('document', 'NN'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(결합문장)) #태깅하여 정보 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a9f7f0",
   "metadata": {},
   "source": [
    "- 앞으로 맞춤법이 틀렸을 때 처리하는 작업이 더 필요 -> 처리해야지 분석이 가능\n",
    "- 예를들어 줄임말들을 자동으로 바꾸는 작업들 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
