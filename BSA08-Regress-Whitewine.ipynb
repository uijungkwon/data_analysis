{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libear Regression & Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression  \n",
    "import statsmodels.api as sm # 통계학적인 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1     0\n",
       "x2     0\n",
       "x3     0\n",
       "x4     0\n",
       "x5     0\n",
       "x6     0\n",
       "x7     0\n",
       "x8     0\n",
       "x9     0\n",
       "x10    0\n",
       "x11    0\n",
       "y      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitedata = pd.read_csv(\"white.csv\")   # dataframe\n",
    "whitedata.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1    x2    x3    x4     x5    x6     x7      x8    x9   x10   x11  y\n",
       "0  7.0  0.27  0.36  20.7  0.045  45.0  170.0  1.0010  3.00  0.45   8.8  6\n",
       "1  6.3  0.30  0.34   1.6  0.049  14.0  132.0  0.9940  3.30  0.49   9.5  6\n",
       "2  8.1  0.28  0.40   6.9  0.050  30.0   97.0  0.9951  3.26  0.44  10.1  6\n",
       "3  7.2  0.23  0.32   8.5  0.058  47.0  186.0  0.9956  3.19  0.40   9.9  6\n",
       "4  7.2  0.23  0.32   8.5  0.058  47.0  186.0  0.9956  3.19  0.40   9.9  6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitedata.head()  # whitedata.tail() # 수치데이터로만 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = whitedata.y  # whitedata[\"y\"] 같은의미 -> 반응변수\n",
    "x = whitedata.x1 # 설명변수\n",
    "plt.scatter(x,y,color=\"blue\"); plt.show()       # 산점도 -> 시각화 : 음의 기울기를 가짐 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = whitedata[\"x1\"].to_frame() # 설명변수 1개를 가져옴 , 시리즈를 데이터프레임으로 변환\n",
    "y = whitedata.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1192889886319587 6.695610039009974\n"
     ]
    }
   ],
   "source": [
    "slm = LinearRegression().fit(x,y) # linear regression에 적합시킴       \n",
    "w, b = slm.coef_[0], slm.intercept_ #codf = B1, intercept = B0\n",
    "print(w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8 14.2\n"
     ]
    }
   ],
   "source": [
    "x0, x1 = x[\"x1\"].min(), x[\"x1\"].max() # 최소값과 최대값을 구함 \n",
    "print(x0, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y,color=\"blue\")\n",
    "plt.plot([x0,x1],[w*x0+b,w*x1+b],'r'); plt.show() # 기울기에 맞는 선을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.013\n",
      "Model:                            OLS   Adj. R-squared:                  0.013\n",
      "Method:                 Least Squares   F-statistic:                     64.08\n",
      "Date:                Mon, 22 May 2023   Prob (F-statistic):           1.48e-15\n",
      "Time:                        15:04:26   Log-Likelihood:                -6322.8\n",
      "No. Observations:                4898   AIC:                         1.265e+04\n",
      "Df Residuals:                    4896   BIC:                         1.266e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          6.6956      0.103     65.057      0.000       6.494       6.897\n",
      "x1            -0.1193      0.015     -8.005      0.000      -0.149      -0.090\n",
      "==============================================================================\n",
      "Omnibus:                       29.986   Durbin-Watson:                   1.657\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               31.513\n",
      "Skew:                           0.166   Prob(JB):                     1.44e-07\n",
      "Kurtosis:                       3.211   Cond. No.                         57.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y, sm.add_constant(x))   # sm.OLS(y,x)와 비교 => x만 집어넣으면 B0를 계산하지 않음\n",
    "results = model.fit()   # sm.OLS(y, sm.add_constant(x)).fit()\n",
    "print(results.summary()) # 위와 다르게 설명력 있는 모델임을 확인 할 수 있음 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiple linear regression # 다중 선형 회귀\n",
    "X = whitedata.drop([\"y\"],axis=1)\n",
    "y = whitedata[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.00846101e-02 -1.70374343e+00  5.69767648e-02  8.17351234e-02\n",
      " -1.64381383e-02  4.96141486e-03 -4.74149230e-04 -1.48223181e+02\n",
      "  7.49786197e-01  7.33900620e-01  2.08766177e-01]\n"
     ]
    }
   ],
   "source": [
    "lrm = LinearRegression(n_jobs=-1)      # fit_intercept=True  # -1: 지금있는 모든 core를 모두 사용하라는 뜻\n",
    "result = lrm.fit(X_train, y_train) \n",
    "print(result.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x1' 'x2' 'x3' 'x4' 'x5' 'x6' 'x7' 'x8' 'x9' 'x10' 'x11']\n"
     ]
    }
   ],
   "source": [
    "print(result.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.13867211 4.87485387 5.80282258 6.02253147 6.30505131 6.55048122\n",
      " 5.98089896 6.06284824 5.56466996 5.94534116]\n"
     ]
    }
   ],
   "source": [
    "forecast = lrm.predict(X_test)\n",
    "print(forecast[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2480396226265077\n"
     ]
    }
   ],
   "source": [
    "accuracy = lrm.score(X_test, y_test)    # 결정계수 Y hat 과 Y를 비교하여 정확도를 비교\n",
    "print(accuracy) # 정확도가 낮다고 판단할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.294\n",
      "Model:                            OLS   Adj. R-squared:                  0.291\n",
      "Method:                 Least Squares   F-statistic:                     129.1\n",
      "Date:                Mon, 22 May 2023   Prob (F-statistic):          3.70e-248\n",
      "Time:                        15:04:27   Log-Likelihood:                -3878.0\n",
      "No. Observations:                3428   AIC:                             7780.\n",
      "Df Residuals:                    3416   BIC:                             7854.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        147.5394     21.311      6.923      0.000     105.755     189.324\n",
      "x1             0.0801      0.025      3.246      0.001       0.032       0.128\n",
      "x2            -1.7037      0.136    -12.503      0.000      -1.971      -1.437\n",
      "x3             0.0570      0.117      0.489      0.625      -0.172       0.286\n",
      "x4             0.0817      0.009      9.368      0.000       0.065       0.099\n",
      "x5            -0.0164      0.687     -0.024      0.981      -1.363       1.330\n",
      "x6             0.0050      0.001      4.790      0.000       0.003       0.007\n",
      "x7            -0.0005      0.000     -1.061      0.289      -0.001       0.000\n",
      "x8          -148.2232     21.632     -6.852      0.000    -190.635    -105.811\n",
      "x9             0.7498      0.124      6.048      0.000       0.507       0.993\n",
      "x10            0.7339      0.121      6.082      0.000       0.497       0.971\n",
      "x11            0.2088      0.028      7.557      0.000       0.155       0.263\n",
      "==============================================================================\n",
      "Omnibus:                       65.953   Durbin-Watson:                   1.982\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              123.067\n",
      "Skew:                           0.114   Prob(JB):                     1.89e-27\n",
      "Kurtosis:                       3.900   Cond. No.                     3.54e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.54e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y_train, sm.add_constant(X_train)) \n",
    "results = model.fit()  \n",
    "print(results.summary())  #결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO, Ridge regression\n",
    "\n",
    "- Elastic net\n",
    "$$ \\min_{\\beta \\in R^p} \\left\\{ ||y- X \\beta||_2^2 + \\lambda_1 ||\\beta||_1 + \\lambda_2 ||\\beta||_2^2 \\right\\} $$\n",
    "- Lasso : $\\lambda_2 = 0$\n",
    "- Ridge : $\\lambda_1 = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 다음에 시작 \n",
    "from sklearn.linear_model import Lasso, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "ridge = Ridge(alpha=0.1)  # alpha=0: OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1350119050228873 [-0.         -0.          0.          0.00658765 -0.          0.00931903\n",
      " -0.0026721  -0.          0.          0.          0.26000292]\n"
     ]
    }
   ],
   "source": [
    "lasso.fit(X_train, y_train)\n",
    "print(lasso.intercept_ , lasso.coef_ )# 추정한 값이 0.1보다 더 작으면 기각시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.98542298 5.39795764 5.75828732 5.94075017 6.3486235  6.35493312\n",
      " 5.74667097 6.083002   5.67070478 5.79674228]\n"
     ]
    }
   ],
   "source": [
    "forecast = lasso.predict(X_test) # 테스트 데이터로 예측함\n",
    "print(forecast[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57998542 0.57993849 0.58026641 0.58096906 0.58204652]\n",
      " [0.60919867 0.60964528 0.61048226 0.61134903 0.61251897]\n",
      " [0.60091517 0.60073638 0.60097051 0.60161758 0.60267759]\n",
      " [0.59410275 0.59459949 0.59552597 0.59688219 0.59866819]\n",
      " [0.57863237 0.57832669 0.57840395 0.57886158 0.57970142]\n",
      " [0.54396721 0.54452774 0.54550652 0.5469035  0.54863308]\n",
      " [0.55135949 0.55188251 0.55279163 0.55408688 0.55547655]\n",
      " [0.56200709 0.561993   0.56253328 0.56350646 0.56486984]\n",
      " [0.55846186 0.55889092 0.55976527 0.56108471 0.56284697]\n",
      " [0.57317467 0.57519277 0.57762293 0.58046507 0.5835661 ]]\n"
     ]
    }
   ],
   "source": [
    "## training-validation procedure(반복 with train-test-split) # 무작위로 10번 test # 설명변수가 많은경우 모델을 fitting하면서 설명변수를 선택할 때 사용, 약간의 bias가 발생할 수 있다.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "result = np.zeros((10,5))\n",
    "a = [0.001, 0.002, 0.003, 0.004, 0.005] # 유의수준 지정 -> 0.001을 선택하는 것이 좋음 \n",
    "for step in range(10):\n",
    "    X0, X1, y0, y1 = train_test_split(X, y, test_size=0.3)\n",
    "    for choice in range(len(a)):\n",
    "        lasso = Lasso(alpha=a[choice])      # sklearn.preprocessing.StandardScaler\n",
    "        lasso.fit(X0, y0); forecast = lasso.predict(X1)\n",
    "        result[step,choice] = mean_squared_error(y1,forecast)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.575180\n",
       "1    0.575573\n",
       "2    0.576387\n",
       "3    0.577573\n",
       "4    0.579101\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(result)\n",
    "result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##5.22수업내용 업데이트 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitedata[\"good\"] = (whitedata.y > 5).astype(float) #good 칼럼의 데이터만 가져옴\n",
    "\n",
    "y_binary = whitedata[\"good\"] #target value\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.508625\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "# statmodels - sm에서 함수 사용 \n",
    "logit_sm = sm.Logit(y_train, sm.add_constant(X_train)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   good   No. Observations:                 3428\n",
      "Model:                          Logit   Df Residuals:                     3416\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Mon, 22 May 2023   Pseudo R-squ.:                  0.2100\n",
      "Time:                        15:06:52   Log-Likelihood:                -1743.6\n",
      "converged:                       True   LL-Null:                       -2206.9\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.101e-191\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        202.1746     77.031      2.625      0.009      51.196     353.153\n",
      "x1             0.0022      0.083      0.026      0.979      -0.160       0.164\n",
      "x2            -5.8583      0.487    -12.033      0.000      -6.813      -4.904\n",
      "x3             0.1649      0.371      0.445      0.657      -0.562       0.892\n",
      "x4             0.1498      0.030      4.962      0.000       0.091       0.209\n",
      "x5             0.9854      2.091      0.471      0.637      -3.113       5.083\n",
      "x6             0.0112      0.003      3.344      0.001       0.005       0.018\n",
      "x7            -0.0022      0.001     -1.564      0.118      -0.005       0.001\n",
      "x8          -215.0109     78.140     -2.752      0.006    -368.163     -61.859\n",
      "x9             1.0349      0.417      2.479      0.013       0.217       1.853\n",
      "x10            2.3811      0.434      5.481      0.000       1.530       3.233\n",
      "x11            0.8020      0.103      7.779      0.000       0.600       1.004\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(logit_sm.summary()) #logisitic regression 결과를 표로 작성 #X1는 필요없고 그 나머지는 유의하다고 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: const    202.174579\n",
      "x1         0.002172\n",
      "x2        -5.858328\n",
      "x3         0.164871\n",
      "x4         0.149811\n",
      "x5         0.985393\n",
      "x6         0.011172\n",
      "x7        -0.002212\n",
      "x8      -215.010948\n",
      "x9         1.034857\n",
      "x10        2.381093\n",
      "x11        0.801961\n",
      "dtype: float64\n",
      "Eta: 1044    1.135539\n",
      "3224    2.072523\n",
      "2808   -0.131601\n",
      "3382    2.380944\n",
      "295    -0.762854\n",
      "728     1.427865\n",
      "4772   -0.486029\n",
      "4053   -0.015095\n",
      "361    -1.930199\n",
      "1466    1.976535\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameters:\",logit_sm.params)# 파라미터 출력\n",
    "print(\"Eta:\", logit_sm.fittedvalues[0:10])# 70%(training data) 중에 제일먼저 뽑힌 데이터 번호가 1044! 확률이 0.5이상이면 좋고 이하면 나쁨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob: 828     0.871299\n",
      "1621    0.131395\n",
      "3091    0.633535\n",
      "2010    0.793015\n",
      "1433    0.876213\n",
      "1101    0.943365\n",
      "3349    0.782047\n",
      "2262    0.800305\n",
      "4600    0.524013\n",
      "1318    0.772940\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "muhat = logit_sm.predict(sm.add_constant(X_test)) #새로운 데이터로 타겟값을 예측 \n",
    "print(\"prob:\", muhat[0:10])# 뮤값 즉 모평균의값을 출력함 , 0.5이상이면 good 이하면 bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828     1\n",
      "1621    0\n",
      "3091    1\n",
      "2010    1\n",
      "1433    1\n",
      "1101    1\n",
      "3349    1\n",
      "2262    1\n",
      "4600    1\n",
      "1318    1\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "yhat = (muhat > 0.5).astype(int) # true =1, false=0 # y예측값을 구함\n",
    "print(yhat[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[238 222]\n",
      " [151 859]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "cm = confusion_matrix(y_test, yhat) #정확도 매트릭스를 사용하여 y의 테스트값과, 예측값인 yhat 값 비교\n",
    "print (\"Confusion Matrix : \\n\", cm) \n",
    "##TP FN   (실제 x 예측)\n",
    "##FP TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy =  0.7462585034013606\n"
     ]
    }
   ],
   "source": [
    "# accuracy score of the model\n",
    "print('Test accuracy = ', accuracy_score(y_test, yhat)) # 정확도 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.507797\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>good</td>       <th>  No. Observations:  </th>   <td>  4898</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  4892</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 22 May 2023</td> <th>  Pseudo R-squ.:     </th>   <td>0.2035</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>15:21:58</td>     <th>  Log-Likelihood:    </th>  <td> -2487.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -3122.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.207e-272</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -9.9599</td> <td>    0.479</td> <td>  -20.797</td> <td> 0.000</td> <td>  -10.899</td> <td>   -9.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>        <td>   -6.7043</td> <td>    0.394</td> <td>  -17.011</td> <td> 0.000</td> <td>   -7.477</td> <td>   -5.932</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>        <td>    0.0654</td> <td>    0.008</td> <td>    8.407</td> <td> 0.000</td> <td>    0.050</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>        <td>    0.0092</td> <td>    0.002</td> <td>    4.148</td> <td> 0.000</td> <td>    0.005</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>       <td>    1.3013</td> <td>    0.331</td> <td>    3.935</td> <td> 0.000</td> <td>    0.653</td> <td>    1.949</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>       <td>    1.0799</td> <td>    0.041</td> <td>   26.567</td> <td> 0.000</td> <td>    1.000</td> <td>    1.160</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                   good   No. Observations:                 4898\n",
       "Model:                          Logit   Df Residuals:                     4892\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Mon, 22 May 2023   Pseudo R-squ.:                  0.2035\n",
       "Time:                        15:21:58   Log-Likelihood:                -2487.2\n",
       "converged:                       True   LL-Null:                       -3122.7\n",
       "Covariance Type:            nonrobust   LLR p-value:                1.207e-272\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -9.9599      0.479    -20.797      0.000     -10.899      -9.021\n",
       "x2            -6.7043      0.394    -17.011      0.000      -7.477      -5.932\n",
       "x4             0.0654      0.008      8.407      0.000       0.050       0.081\n",
       "x6             0.0092      0.002      4.148      0.000       0.005       0.014\n",
       "x10            1.3013      0.331      3.935      0.000       0.653       1.949\n",
       "x11            1.0799      0.041     26.567      0.000       1.000       1.160\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 변수지정 fomula.api  ## 이방법이 모델링하기 쉽기 때문에 많이 사용!\n",
    "##공부할것 : 상호작용을 하기 위해서는 어떤 모델을 생성할 필요가 있나? ->파이널 프로젝트 \n",
    "import statsmodels.formula.api as smf # 직접 데이터의 모델을 설정\n",
    "model = \"good ~ x2+x4+x6+x10+x11\" #칼럼 X1~X11을 사용해여 모델 생성\n",
    "logit_smf = smf.logit(formula=str(model),data=whitedata).fit()\n",
    "logit_smf.summary() ##logistic regression의 결과를 표로 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn : “statsmodels”과 다른 설정\n",
    "#sklearn사용 !\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SM-PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(penalty=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(penalty=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(penalty=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logitS = LogisticRegression(penalty=None)  ## C=1/alpha=1, penality=\"l2\" {\"l1\",\"l2\",\"elasticnet\",None}\n",
    "logitS.fit(X_train, y_train)  #기본적으로 분석할 때 1을 포함   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.65831808e-01 -6.60393173e+00 -4.55204322e-01  6.10587409e-02\n",
      "  -5.53974022e-01  1.10710499e-02 -2.68518619e-03 -2.40885588e+00\n",
      "  -7.39746026e-01  2.20586985e+00  9.87125075e-01]] [-2.41690669]\n"
     ]
    }
   ],
   "source": [
    "print(logitS.coef_, logitS.intercept_)     #상관계수와 B0 값 출력, 위 모델의 coef값과 비교  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The choice of the algorithm depends on the penalty chosen. Supported penalties by solver:\n",
    " - lbfgs’ - [‘l2’, None]\n",
    "\n",
    " - liblinear’ - [‘l1’, ‘l2’]\n",
    " - 'newton-cg’ - [‘l2’, None]\n",
    " - 'newton-cholesky’ - [‘l2’, None]\n",
    " - 'sag’ - [‘l2’, None]\n",
    " - 'saga’ - [‘elasticnet’, ‘l1’, ‘l2’, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SM-PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logitL = LogisticRegression(penalty=\"l1\",solver=\"saga\")  # LASSO , C = 1/alpha, solver를 saga로 적용 후 사용가능함, 라쏘는 기준값 이하로 내려가면 0으로 보내버림\n",
    "logitL.fit(X_train, y_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24486208 0.75513792]\n",
      " [0.58471433 0.41528567]\n",
      " [0.36855233 0.63144767]\n",
      " [0.2565897  0.7434103 ]\n",
      " [0.16571528 0.83428472]\n",
      " [0.13910636 0.86089364]\n",
      " [0.28382279 0.71617721]\n",
      " [0.23968072 0.76031928]\n",
      " [0.4277204  0.5722796 ]\n",
      " [0.26209616 0.73790384]]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "muL = logitL.predict_proba(X_test) # 뮤 햇을 구하여 muL 생성 (예측 확률 구함)\n",
    "yhat = logitL.predict(X_test)  # 예측값을 생성 \n",
    "print(muL[0:10])\n",
    "print(yhat[0:10]) #결과값은 0 ,1 로 표현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6843537414965987"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logitL.score(X_test, y_test)# 예측값의 정확도를 출력\n",
    "\n",
    "##5.22일 수업 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다범주 로짓 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets   \n",
    "# iris data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.discrete.discrete_model import MNLogit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlogit_sm = MNLogit(Y,sm.add_constant(X)).fit(maxiter=100,method=\"bfgs\")\n",
    "mlogit_sm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = mlogit_sm.predict(sm.add_constant(X))\n",
    "print(prob[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.argmax(prob,1)\n",
    "print(yhat[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO with statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlogit_sm = MNLogit(Y,sm.add_constant(X))\n",
    "mlogit_smL = mlogit_sm.fit_regularized(method=\"l1\", alpha=0.5)\n",
    "mlogit_smL.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhatL = np.argmax(mlogit_smL.predict(sm.add_constant(X)),1)\n",
    "print(yhatL[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn\n",
    "mlogitR = LogisticRegression(C=1e5)  # multi_class=\"auto\" {'ovr','multinomial','auto'}  \n",
    "mlogitR.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muR = mlogitR.predict_proba(X)\n",
    "yhatR = np.argmax(muR,1)\n",
    "print(muR[0:10])\n",
    "print(yhatR[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그림으로 표시\n",
    "h = .02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = mlogitR.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "# put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(8, 7))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Sepal length'); plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max());  plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(()); plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
